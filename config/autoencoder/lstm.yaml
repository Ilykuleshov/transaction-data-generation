name: lstm

autoencoder_core:
  _target_: src.networks.autoencoder_core.NLPLSTM
  encoder:
    _target_: ptls.nn.RnnSeqEncoder
    trx_encoder:
      _target_: ptls.nn.TrxEncoder
      use_batch_norm_with_lens: True
      norm_embeddings: False
      embeddings_noise: 0.0003
      embeddings: 
        mcc_code:   
          in: 344
          out: 24
      numeric_values: {amount: identity}
    hidden_size: 1024
    bidir: False
    trainable_starter: static
    type: lstm
    is_reduce_sequence: False
  hidden_size: 2048
  num_layers: 2
  proj_size: 1024


# for ease of access
n_mccs: ${.autoencoder_core.encoder.trx_encoder.embeddings.mcc_code.in}

weights_path: weights/coles_best_state_dict.pth
loss_weights:
  mcc: 100
  amount: 1
freeze_embed: True
unfreeze_after: 50

data_split:
  test_size: .2
  val_size: .2
  
learning_params:
  epochs: 50
  lr: .001
  weight_decay: .00005
  step_size: 30
  gamma: .9
  train_batch_size: 32
  val_batch_size: 8
  train_num_workers: 4
  val_num_workers: 4
  early_stopping:
    min_delta: .01
    patience: 5
  
  accum_grad_batches: 4
